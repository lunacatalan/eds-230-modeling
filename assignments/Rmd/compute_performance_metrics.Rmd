---
author: "Luna & Sofia"
title: "compute_metrics"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

Explanation: We decided to investigate the metric high stream flow
because these are important to understand for flooding and drought risk.
Additionally, it affects ecosystem and vegetation health, and can help
design irrigation solutions that are on a time basis.

The model was ok, with a combined error of 0.65 though the predicted and
observed outcomes are highly correlated which is a good sign.

![](images/Screenshot%202024-04-23%20at%202.22.01%20PM.png)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(sensitivity)
library(tidyverse)
library(purrr)
library(ggpubr)
```

# Comparing model and observed time series output

When evaluating a model - Always plot first

Plotting and what it can tell you

-   plot through time

    -   look for differences in performance in different periods
    -   does model capture seasonlity, temporal trends

-   some things to think about that might help make it easier to "see"
    differences betwee observed time series and mdoelled time series

    -   consider appropriate y-axis
    -   consider picking a window (subset in x-axis)

-   plot x-y (observed vs model)

    -   look for bios (error) (using a 1 to 1 line are points always
        above or below)
    -   look for errors associated with particular magnitdues (e.g high
        or low values)

```{r simple, message=FALSE, warning=FALSE}

sager = read.table("../data/sager.txt", header=T)
head(sager)

# add date
sager = sager %>% mutate(date = paste(day,month,year, sep="/"))
sager$date = as.Date(sager$date,"%d/%m/%Y")

# plot
sagerl = sager %>% pivot_longer(cols=c("model","obs"), names_to="source",
                                  values_to="flow")

# basic plot
ggplot(sagerl, aes(date, flow, col=source, linetype=source))+geom_line()

# change axis to get a closer look at performance at low values
# when you have high dynamic range (lots of large and small values), taking log can help
# with visualization
ggplot(sagerl, aes(date, flow, col=source, linetype=source))+geom_line()+scale_y_continuous(trans="log")+labs(y="streamflow mm/day")

# look at it another way
ggplot(sager, aes(obs, model))+geom_point()+geom_abline(intercept=0, slope=1, col="red")


```

# Measure Performance using different metrics

Once you've plotted, consider some metrics that summarize performance

Think about what part of the time-series is of interest

-   long term means (bims)
-   year to year variablity
-   peak or minimum events

Create performance metrics that are relevant to the model application

Lets start though with some simple metrics

```{r message=FALSE, warning=FALSE}


source("../../R/nse.R")

source("../../R/relerr.R")


source("../../R/cper.R")

nse
relerr
cper
nse(m=sager$model, o=sager$obs)

relerr(m=sager$model, o=sager$obs)*100

cper(m=sager$model, o=sager$obs, weight.nse=0.8)


```

# Scale and subsetting

Performance also depends on the 'what' you are evaluating

-   time steps (annual, daily, monthly)

-   selection of particular periods of time

# try another metric

-   high streamflow

```{r, message=FALSE, warning=FALSE}

# use sagerl
sagerl

sagerl = sager %>% pivot_longer(cols=c("model","obs"), names_to="source",
                                  values_to="flow")

subset <- sagerl %>% 
  filter(year == 1965:1966)

# basic plot looking at yearly flow
ggplot(subset, aes(date, flow, col=source, linetype=source)) + 
  geom_line()

# turn your evaluation metric into a function
source("../../R/compute_highflowmetrics.R")
compute_highflowmetrics
compute_highflowmetrics(m=sager$model,o=sager$obs, month=sager$month, day=sager$day, year=sager$year, wy=sager$wy)

# use different low flow months
compute_highflowmetrics(m=sager$model,o=sager$obs, month=sager$month, day=sager$day, year=sager$year, wy=sager$wy, 
                        high_flow_months = c(1:3)) # select based on time series

```

# Create a combined metric

Sometime you want to summarize everything in one number

Especially if you want to rank different models or create indices like
Sobol Sensitivity Indices

```{r, message=FALSE, warning=FALSE}

perf = compute_highflowmetrics(m=sager$model,o=sager$obs, month=sager$month, day=sager$day, year=sager$year, wy=sager$wy, high_flow_months = c(1:3))

perf = as.data.frame((perf))
# remember you want error to be low but correlation to be high 
# so we need to transform in some way

# normalize by max error = if error is greater than this we don't care
# many ideas -  maybe 50% of mean daily summer observed low flow
tmp = sager %>% subset(month %in% c(7:9)) 
errmax = mean(tmp$obs)*0.5

perf = perf %>% mutate(annual_max_err_trans = max(0,(1-abs(annual_max_err/errmax) )))
      
# for monthly we can do a simpler thing to find maximum allowable errror   
tmp = sager %>% subset(month %in% c(7:9)) %>% group_by(wy, month) %>% summarize(obs=sum(obs))

errmax = mean(tmp$obs)*0.5
 
perf = perf %>% mutate(high_month_err_trans = max(0,(1-abs(high_month_err/errmax) )))

# now we have 4 measures that we can combine together

perf = perf %>% 
  mutate(combined = (annual_max_cor + annual_max_err_trans + high_month_err_trans + high_month_cor)/4)

perf
# or weight differently - we know that minimum flows are hard to get to weight those differently

perf = perf %>% 
  mutate(combined2 = 0.1*annual_max_cor + 0.1*annual_max_err_trans + 0.4*high_month_err_trans+ 0.4*high_month_cor)

perf

# easier to put all this in a function


```

# Calibration

Calibration is picking parameter sets based on performance evaluation

Apply metrics over multiple outputs (generated by running across many
parameters sets)

Ideally we'd generate these parameter "smartly" - LHS or Sobol sampling

Example - a dataset where each column is a different model run for
Sagehen Creek (using different parameters)

don't worry about what the parameters are for now

File Name \* sagerm.txt

```{r multipel, message=FALSE, warning=FALSE}
# multiple results - lets say we've run the model for multiple years, each column
# is streamflow for a different parameter set
msage = read.table("../data/sagerm.txt", header=T)

# lets say we know the start date from our earlier output
msage$date = sager$date
msage$month = sager$month
msage$year = sager$year
msage$day = sager$day
msage$wy = sager$wy

# and we still have observed data from above
msage = left_join(msage, sager[,c("obs","date")], by=c("date"))

# subset for split sample calibration
short_msage = subset(msage, wy < 1975)


# how can we plot all results - lets plot water year 1970 otherwise its hard to see
msagel = msage %>% 
  pivot_longer(cols=!c(date, month, year, day,wy), names_to="run", values_to="flow")


p1=ggplot(subset(msagel, wy == 1978), # subset for only this year
          aes(as.Date(date), flow, col=run)) + 
  geom_line() + 
  theme(legend.position = "none")
p1
# lets add observed streamflow
p1 + geom_line(data=subset(sager, wy == 1978), aes(as.Date(date), obs), 
               size=2, col="black", linetype=2) +
  labs(y="Streamflow", x="Date")
```

Calibration with years above 1988

```{r message=FALSE, warning=FALSE}
# subset for split sample calibration
short_msage = subset(msage, wy < 1976)

# compute performance measures for output from all parameters
res <- short_msage %>% 
  select(!c("date","month","year","day","wy","obs")) %>%
  map_dbl(nse, short_msage$obs)


head(res)

# another example using our low flow statistics
# use apply to compute for all the data
# using the updated high flow metrics routing that also computed combined metrics

source("../../R/compute_highflowmetrics_all.R")
res = short_msage %>% select(-date, -month, -day, -year, -wy, -obs ) %>%
  map_df(compute_highflowmetrics_all, o=short_msage$obs, month=short_msage$month,
        day=short_msage$day, year=short_msage$year, wy=short_msage$wy)


# interesting to look at range of metrics - could use this to decide on
# acceptable values
summary(res)


# graph range of performance measures
resl = res %>% 
  pivot_longer(cols=everything(), names_to="metric", values_to="value")
ggplot(resl, aes(metric, value))+
  geom_boxplot()+
  facet_wrap(~metric, scales="free")
```

```{r message=FALSE, warning=FALSE}
# try this
# assign an identifier to each row, use the same identify for columns of original streamflow data
# we can then use that to pick data
res$run = seq(from=1,to=nrow(res))

colnames(msage)=c(res$run, "date", "month", "year","day","wy", "obs")

colnames(msage)

# best one
best = res[which.max(res$combined),]
worst = res[which.min(res$combined),]

best
worst
```

Plot the best run:

```{r message=FALSE, warning=FALSE, error = FALSE}
msagel <- short_msage %>% 
  pivot_longer(cols=!c(date, month, year, day, wy, obs), names_to="run", values_to="flow")
  
# post calibration based on BEST run 
ggplot(subset(msagel, run == best$run), 
       aes(date, flow)) + 
  geom_line(color = "black") + 
  # plotting based on observations
  geom_line(data = msagel, aes(date, obs), col="red") + 
  theme_classic() +
  labs(title = "Calibrated High Streamflow")

```

Compare runs

```{r}
compruns = msagel %>% select(best$sim, worst$sim, date, obs, month, day, year, wy)
 compruns = subset(compruns, wy > 1970)
 compruns_mwy = compruns %>% select(-c(day,date, year)) %>% group_by(month, wy) %>%
        summarize(across(everything(), mean))
```
